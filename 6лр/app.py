from flask import Flask, request, jsonify, g
import logging
import time
import os
import glob
import psycopg2 
from psycopg2 import extras # –ù—É–∂–µ–Ω –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è
import redis 
import json # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (—Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥) –≤ Redis
from datetime import datetime

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL (—á–∏—Ç–∞—é—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è Docker Compose/ .env) ---
# –•–æ—Å—Ç—ã db –∏ cache - —ç—Ç–æ –∏–º–µ–Ω–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ –≤ docker-compose.yml
DB_HOST = os.environ.get('DB_HOST', 'db')
DB_NAME = os.environ.get('DB_NAME', 'mydatabase')
DB_USER = os.environ.get('DB_USER', 'user')
DB_PASS = os.environ.get('DB_PASS', 'password')

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Redis ---
REDIS_HOST = os.environ.get('REDIS_HOST', 'cache') # –ò–º—è —Å–µ—Ä–≤–∏—Å–∞ 'cache' –≤ docker-compose
REDIS_PORT = int(os.environ.get('REDIS_PORT', 6379))
REDIS_CACHE_TIMEOUT = 30 # –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
REDIS_KEY_ALL_BOOKS = 'all_books'

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
LOG_FILE = 'books_app.log' # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–∑ —Ç–≤–æ–µ–≥–æ —Ñ–∞–π–ª–∞
MAX_LOG_SIZE = 5 * 1024 * 1024  # 5 MB
BACKUP_COUNT = 3 

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask –∏ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False

# [–û—Å—Ç–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å SimpleFileHandler –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –≤ lab5.py,
# –µ—Å–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É, —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å —Ç–≤–æ–π –∫–æ–¥ —Å–∏–ª—å–Ω–æ]
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –ë–î –∏ Redis ---
redis_client = None

def get_db_connection():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–µ."""
    if 'db_conn' not in g or g.db_conn.closed:
        try:
            g.db_conn = psycopg2.connect(
                host=DB_HOST,
                database=DB_NAME,
                user=DB_USER,
                password=DB_PASS
            )
            logger.info("–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å PostgreSQL.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ PostgreSQL: {e}")
            # –í–Ω—É—Ç—Ä–∏ Docker Compose –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä 'db' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–µ–Ω
            raise e
    return g.db_conn

@app.teardown_appcontext
def close_db_connection(exception):
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
    db_conn = g.pop('db_conn', None)
    if db_conn is not None:
        db_conn.close()
        logger.debug("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å PostgreSQL –∑–∞–∫—Ä—ã—Ç–æ.")


def init_db_and_redis():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ë–î (—Ç–∞–±–ª–∏—Ü—ã) –∏ Redis (—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ) —Å –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è."""
    global redis_client
    max_retries = 15 
    db_connected = False
    redis_connected = False
    
    # 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —Å —Ä–µ—Ç—Ä–∞—è–º–∏
    for i in range(max_retries):
        if db_connected: break
        try:
            conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS, connect_timeout=3)
            with conn.cursor() as cursor:
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS books (
                        id SERIAL PRIMARY KEY,
                        title VARCHAR(255) NOT NULL,
                        author VARCHAR(255) NOT NULL,
                        year INTEGER
                    )
                ''')
                conn.commit()
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                cursor.execute("SELECT COUNT(*) FROM books")
                if cursor.fetchone()[0] == 0:
                    cursor.execute('''
                        INSERT INTO books (title, author, year) VALUES 
                        (%s, %s, %s), (%s, %s, %s)
                    ''', [
                        ('–í–æ–π–Ω–∞ –∏ –º–∏—Ä', '–õ–µ–≤ –¢–æ–ª—Å—Ç–æ–π', 1869),
                        ('–ü—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–µ –∏ –Ω–∞–∫–∞–∑–∞–Ω–∏–µ', '–§—ë–¥–æ—Ä –î–æ—Å—Ç–æ–µ–≤—Å–∫–∏–π', 1866)
                    ])
                    conn.commit()
                    logger.info("–î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É PostgreSQL.")
                
            conn.close()
            db_connected = True
            logger.info("–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PostgreSQL.")
        except Exception as e:
            logger.warning(f"–û–∂–∏–¥–∞–Ω–∏–µ PostgreSQL. –ü–æ–ø—ã—Ç–∫–∞ {i+1}/{max_retries}. –û—à–∏–±–∫–∞: {e}")
            time.sleep(2)
            
    if not db_connected:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ PostgreSQL –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫. –ö–Ω–∏–≥–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        
    # 2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis —Å —Ä–µ—Ç—Ä–∞—è–º–∏
    for i in range(max_retries):
        if redis_connected: break
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º host 'cache', –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ docker-compose.yml
            redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, decode_responses=True, socket_timeout=3)
            redis_client.ping()
            redis_connected = True
            logger.info("–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis.")
        except Exception as e:
            logger.warning(f"–û–∂–∏–¥–∞–Ω–∏–µ Redis. –ü–æ–ø—ã—Ç–∫–∞ {i+1}/{max_retries}. –û—à–∏–±–∫–∞: {e}")
            time.sleep(2)
            
    if not redis_connected:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–æ.")
        redis_client = None

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
# [–ó–¥–µ—Å—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ç–≤–æ–π –∫–æ–¥ –¥–ª—è request_stats, log_request_info, log_response_info, update_statistics]
# ... (–û—Å—Ç–∞–≤–∏–ª —Ç–≤–æ–π –∫–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
request_stats = {
    'total_requests': 0,
    'average_time': 0,
    'endpoints': {}
}

def log_request_info():
    logger.info(f"–í—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å: {request.method} {request.path}")

def log_response_info(response, status_code, execution_time=None):
    if execution_time is not None:
        logger.info(f"–ò—Å—Ö–æ–¥—è—â–∏–π –æ—Ç–≤–µ—Ç: {status_code} –¥–ª—è {request.method} {request.path} - –í—Ä–µ–º—è: {execution_time:.3f} —Å–µ–∫")
    else:
        logger.info(f"–ò—Å—Ö–æ–¥—è—â–∏–π –æ—Ç–≤–µ—Ç: {status_code} –¥–ª—è {request.method} {request.path}")
    return response

def update_statistics(endpoint, execution_time):
    request_stats['total_requests'] += 1
    
    total_time = request_stats['average_time'] * (request_stats['total_requests'] - 1) + execution_time
    request_stats['average_time'] = total_time / request_stats['total_requests']
    
    if endpoint not in request_stats['endpoints']:
        request_stats['endpoints'][endpoint] = {
            'count': 0,
            'total_time': 0,
            'average_time': 0,
            'min_time': float('inf'),
            'max_time': 0
        }
    
    endpoint_stats = request_stats['endpoints'][endpoint]
    endpoint_stats['count'] += 1
    endpoint_stats['total_time'] += execution_time
    endpoint_stats['average_time'] = endpoint_stats['total_time'] / endpoint_stats['count']
    endpoint_stats['min_time'] = min(endpoint_stats['min_time'], execution_time)
    endpoint_stats['max_time'] = max(endpoint_stats['max_time'], execution_time)


app_started = False

# –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
@app.before_request
def before_first_request():
    global app_started
    if not app_started:
        logger.info("=" * 50)
        logger.info("Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ '–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞' –∑–∞–ø—É—â–µ–Ω–æ –∏ –≥–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—Ä–æ—Å–∞–º")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –∏–∑ –±–∞–∑—ã (PostgreSQL)
        try:
            conn = get_db_connection()
            with conn.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM books")
                books_count = cursor.fetchone()[0]
                logger.info(f"–¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ (PostgreSQL): {books_count}")
        except Exception as e:
            # –ù–µ —Å—Ç—Ä–∞—à–Ω–æ, –µ—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è, –≥–ª–∞–≤–Ω–æ–µ —á—Ç–æ Flask —Ä–∞–±–æ—Ç–∞–µ—Ç
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–Ω–∏–≥ –∏–∑ –ë–î: {e}")
            
        logger.info("=" * 50)
        app_started = True

# --- API –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã (–û–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PostgreSQL –∏ Redis) ---

# 1. –ü–û–õ–£–ß–ò–¢–¨ –í–°–ï –ö–ù–ò–ì–ò (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º Redis)
@app.route('/books', methods=['GET'])
def get_books():
    start_time = time.time()
    log_request_info()
    endpoint = "GET /books"
    
    try:
        # 1. –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ Redis
        if redis_client:
            cached_books_json = redis_client.get(REDIS_KEY_ALL_BOOKS)
            if cached_books_json:
                logger.info("–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–Ω–∏–≥ - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–µ—à Redis.")
                response_data = json.loads(cached_books_json)
                response = jsonify(response_data)
                
                execution_time = time.time() - start_time
                update_statistics(endpoint, execution_time)
                log_response_info(response, 200, execution_time)
                return response
        
        # 2. –ï—Å–ª–∏ –Ω–µ—Ç –≤ –∫–µ—à–µ, –ø–æ–ª—É—á–∞–µ–º –∏–∑ PostgreSQL
        conn = get_db_connection()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RealDictCursor –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cursor: 
            cursor.execute("SELECT id, title, author, year FROM books ORDER BY id")
            books_list = cursor.fetchall()
        
        logger.info(f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–Ω–∏–≥. –ù–∞–π–¥–µ–Ω–æ: {len(books_list)}")
        
        response = jsonify(books_list)
        
        # 3. –ö–µ—à–∏—Ä—É–µ–º –≤ Redis
        if redis_client:
            redis_client.set(REDIS_KEY_ALL_BOOKS, json.dumps(books_list), ex=REDIS_CACHE_TIMEOUT) 
            logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ /books —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∫–µ—à–µ Redis.")
            
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        log_response_info(response, 200, execution_time)
        
        return response
    except Exception as e:
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–Ω–∏–≥: {str(e)}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

# 2. –ü–û–õ–£–ß–ò–¢–¨ –û–î–ù–£ –ö–ù–ò–ì–£
@app.route('/books/<int:book_id>', methods=['GET'])
def get_one_book(book_id):
    start_time = time.time()
    log_request_info()
    endpoint = f"GET /books/{book_id}"
    
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cursor:
            cursor.execute("SELECT id, title, author, year FROM books WHERE id = %s", (book_id,))
            book = cursor.fetchone()
        
        if book:
            logger.info(f"–ö–Ω–∏–≥–∞ —Å ID {book_id} –Ω–∞–π–¥–µ–Ω–∞: {book['title']}")
            response = jsonify(book)
            execution_time = time.time() - start_time
            update_statistics(endpoint, execution_time)
            log_response_info(response, 200, execution_time)
            return response
        else:
            logger.warning(f"–ö–Ω–∏–≥–∞ —Å ID {book_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            execution_time = time.time() - start_time
            update_statistics(endpoint, execution_time)
            return jsonify({"error": "–ù–µ—Ç —Ç–∞–∫–æ–π –∫–Ω–∏–≥–∏"}), 404
            
    except Exception as e:
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–Ω–∏–≥–∏ {book_id}: {str(e)}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

# 3. –î–û–ë–ê–í–ò–¢–¨ –ö–ù–ò–ì–£ (—Å–±—Ä–æ—Å –∫–µ—à–∞)
@app.route('/books', methods=['POST'])
def add_book():
    start_time = time.time()
    log_request_info()
    endpoint = "POST /books"
    
    conn = None
    try:
        data = request.get_json()
        logger.info(f"–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–Ω–∏–≥–∏ —Å –¥–∞–Ω–Ω—ã–º–∏: {data}")
        
        required_fields = ['title', 'author', 'year']
        if not data or any(f not in data for f in required_fields):
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–Ω–∏–≥–∏ –±–µ–∑ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π")
            execution_time = time.time() - start_time
            update_statistics(endpoint, execution_time)
            return jsonify({"error": f"–ù—É–∂–Ω—ã {', '.join(required_fields)}"}), 400
        
        conn = get_db_connection()
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cursor:
            # RETURNING id –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å ID –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
            cursor.execute('''
                INSERT INTO books (title, author, year) VALUES (%s, %s, %s)
                RETURNING id
            ''', (data['title'], data['author'], data['year']))
            
            new_id = cursor.fetchone()['id']
            conn.commit()
        
        # –°–±—Ä–æ—Å –∫–µ—à–∞ Redis –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        if redis_client:
            redis_client.delete(REDIS_KEY_ALL_BOOKS)
            logger.info(f"–°–±—Ä–æ—à–µ–Ω –∫–µ—à '{REDIS_KEY_ALL_BOOKS}' –≤ Redis –ø–æ—Å–ª–µ POST –∑–∞–ø—Ä–æ—Å–∞.")
        
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–Ω–∏–≥–∞: ID={new_id}, –ù–∞–∑–≤–∞–Ω–∏–µ='{data['title']}'")
        
        response = jsonify({"id": new_id, **data})
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        log_response_info(response, 201, execution_time)
        
        return response, 201
        
    except Exception as e:
        if conn:
            conn.rollback() # –û—Ç–∫–∞—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–Ω–∏–≥–∏: {str(e)}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

# 4. –ò–ó–ú–ï–ù–ò–¢–¨ –ö–ù–ò–ì–£ (—Å–±—Ä–æ—Å –∫–µ—à–∞)
@app.route('/books/<int:book_id>', methods=['PUT'])
def update_book(book_id):
    start_time = time.time()
    log_request_info()
    endpoint = f"PUT /books/{book_id}"
    
    conn = None
    try:
        data = request.get_json()
        logger.info(f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–Ω–∏–≥–∏ ID={book_id} —Å –¥–∞–Ω–Ω—ã–º–∏: {data}")
        
        conn = get_db_connection()
        
        # –°–æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
        update_parts = []
        update_values = []
        
        if 'title' in data:
            update_parts.append("title = %s")
            update_values.append(data['title'])
        if 'author' in data:
            update_parts.append("author = %s")
            update_values.append(data['author'])
        if 'year' in data:
            update_parts.append("year = %s")
            update_values.append(data['year'])

        if not update_parts:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 200
            return jsonify({"message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"}), 200

        update_values.append(book_id)
        
        sql_query = f"UPDATE books SET {', '.join(update_parts)} WHERE id = %s RETURNING id, title, author, year"
        
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cursor:
            cursor.execute(sql_query, update_values)
            updated_book = cursor.fetchone()
            
            if not updated_book:
                conn.rollback()
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–Ω–∏–≥–∏ ID={book_id}")
                execution_time = time.time() - start_time
                update_statistics(endpoint, execution_time)
                return jsonify({"error": "–ù–µ—Ç —Ç–∞–∫–æ–π –∫–Ω–∏–≥–∏"}), 404
            
            conn.commit()
        
        # –°–±—Ä–æ—Å –∫–µ—à–∞ Redis
        if redis_client:
            redis_client.delete(REDIS_KEY_ALL_BOOKS)
            logger.info(f"–°–±—Ä–æ—à–µ–Ω –∫–µ—à '{REDIS_KEY_ALL_BOOKS}' –≤ Redis –ø–æ—Å–ª–µ PUT –∑–∞–ø—Ä–æ—Å–∞.")
        
        logger.info(f"–ö–Ω–∏–≥–∞ ID={book_id} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
        
        response = jsonify(updated_book)
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        log_response_info(response, 200, execution_time)
        
        return response
        
    except Exception as e:
        if conn:
            conn.rollback()
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–Ω–∏–≥–∏: {str(e)}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

# 5. –£–î–ê–õ–ò–¢–¨ –ö–ù–ò–ì–£ (—Å–±—Ä–æ—Å –∫–µ—à–∞)
@app.route('/books/<int:book_id>', methods=['DELETE'])
def delete_book(book_id):
    start_time = time.time()
    log_request_info()
    endpoint = f"DELETE /books/{book_id}"
    
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cursor:
            cursor.execute("DELETE FROM books WHERE id = %s", (book_id,))
            deleted_count = cursor.rowcount
            conn.commit()
        
        if deleted_count == 0:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–Ω–∏–≥–∏ ID={book_id}")
            execution_time = time.time() - start_time
            update_statistics(endpoint, execution_time)
            return jsonify({"error": "–ù–µ—Ç —Ç–∞–∫–æ–π –∫–Ω–∏–≥–∏"}), 404
        
        # –°–±—Ä–æ—Å –∫–µ—à–∞ Redis
        if redis_client:
            redis_client.delete(REDIS_KEY_ALL_BOOKS)
            logger.info(f"–°–±—Ä–æ—à–µ–Ω –∫–µ—à '{REDIS_KEY_ALL_BOOKS}' –≤ Redis –ø–æ—Å–ª–µ DELETE –∑–∞–ø—Ä–æ—Å–∞.")
            
        logger.info(f"–ö–Ω–∏–≥–∞ ID={book_id} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞.")
        
        response = jsonify({"message": f"–ö–Ω–∏–≥–∞ —Å ID {book_id} —É–¥–∞–ª–µ–Ω–∞"})
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        log_response_info(response, 200, execution_time)
        
        return response, 200
        
    except Exception as e:
        if conn:
            conn.rollback()
        execution_time = time.time() - start_time
        update_statistics(endpoint, execution_time)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∫–Ω–∏–≥–∏: {str(e)}")
        return jsonify({"error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500
        
# [–û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ (logs/info, stats, errorhandler 404/405) –æ—Å—Ç–∞–≤–ª–µ–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π]

# –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–æ–≥–∞—Ö 
@app.route('/logs/info', methods=['GET'])
def get_logs_info():
    # ... (—Ç–≤–æ–π –∫–æ–¥)
    try:
        base_name = LOG_FILE.replace('.log', '')
        log_files = []
        
        for f in glob.glob(f"{base_name}*.log") + glob.glob(LOG_FILE): # –í–∫–ª—é—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
            if os.path.exists(f):
                file_size = os.path.getsize(f)
                log_files.append({
                    "filename": os.path.basename(f),
                    "size_bytes": file_size,
                    "size_mb": round(file_size / (1024 * 1024), 2),
                })
        
        log_files.sort(key=lambda x: x['filename'])
        
        return jsonify({
            "max_size_mb": MAX_LOG_SIZE / (1024 * 1024),
            "backup_count": BACKUP_COUNT,
            "log_files": log_files
        }), 200
        
    except Exception as e:
        return jsonify({"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–æ–≥–∞—Ö: {str(e)}"}), 500

# –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
@app.route('/stats', methods=['GET'])
def get_stats():
    return jsonify(request_stats), 200


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    start_time = time.time()
    logger.warning(f"–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É –º–∞—Ä—à—Ä—É—Ç—É: {request.path}")
    
    response = jsonify({"error": "–ú–∞—Ä—à—Ä—É—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 404
    execution_time = time.time() - start_time
    update_statistics(f"ERROR {request.path}", execution_time)
    
    return response

@app.errorhandler(405)
def method_not_allowed(error):
    start_time = time.time()
    logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–µ—Ç–æ–¥ {request.method} –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞ {request.path}")
    
    response = jsonify({"error": "–ú–µ—Ç–æ–¥ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω"}), 405
    execution_time = time.time() - start_time
    update_statistics(f"ERROR {request.path}", execution_time)
    
    return response

# –ó–ê–ü–£–°–ö
if __name__ == '__main__':
    init_db_and_redis()
    logger.info("–ó–∞–ø—É—Å–∫ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è '–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞'...")
    print("–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω: http://localhost:5000")
    print("\nüìñ –ß—Ç–æ –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å:")
    print("GET    /books          - –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –∫–Ω–∏–≥–∏")
    print("GET    /books/1        - –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–Ω–∏–≥—É 1")
    print("POST   /books          - –¥–æ–±–∞–≤–∏—Ç—å –∫–Ω–∏–≥—É") 
    print("PUT    /books/1        - –∏–∑–º–µ–Ω–∏—Ç—å –∫–Ω–∏–≥—É 1")
    print("DELETE /books/1        - —É–¥–∞–ª–∏—Ç—å –∫–Ω–∏–≥—É 1")
    print("GET    /health         - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–µ—Ä")
    print("GET    /stats          - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    
    app.run(host='0.0.0.0', port=5000, debug=False)